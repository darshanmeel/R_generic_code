---
output: word_document
---
```{r}
#load the csv file and provide the name as lv
filename <- 'LendingClub.csv'
header <- TRUE
filename

clscol='Class'

#run prelim processing
X <- read.csv(file=filename,header=header)
clscolpos <- match(clscol,colnames(X))
X <- X[complete.cases(X),]
X <- moveclasscolintheend(X,clscolpos)
X[,clscolpos] <- as.character(X[,clscolpos])

X[X[,clscolpos]=='Creditworthy',clscolpos] <- '0'
X[X[,clscolpos]=='Uncreditworthy',clscolpos] <- '1'
X[,clscolpos] <- as.factor(as.numeric(X[,clscol]))



#Now fix all the issues you want to with your data which you might have got idea from Pass_1 as well as from your own analytics.

#Now convert all the factor columns to ordered in final model these wont be ordered
factcols <- findallfactorcols(X[,-ncol(X)])
print(factcols)
for (cl in factcols){
  ab <- as.data.frame(table(X[,cl]))
  ab <- ab[order(ab[,2]),]
  nwlvls <- paste(ab[,1],sep=',')
  nwlvls <- as.data.frame(nwlvls)
  nwlvls <- rownames(nwlvls)
  ab <- cbind(ab,nwlvls)
  print (ab)
  X[,cl] <- as.character(X[,cl])
  cl_vc <- X[,cl]
  X[,cl] <- as.numeric(unlist(lapply(cl_vc,function(vl) ab[ab[,1]==vl,3])))
  X[,cl] <- ordered(X[,cl], levels = nwlvls)
}


# Now convert these columns to factor columns and in fact ordered factor columns
numcols_to_be_converted <- c(3,8,11,12,13,14,17,18)
X1 <- convert_num_field_to_ordered_fact_cols(X,numcols_to_be_converted)
X[,numcols_to_be_converted] <- X1
# see whether new cols are converted to fact columns.
str(X)
# Now break the data into 3 parts, train data, test data and valid data as feature selection should always be done on train data and never on test and valid data.
#valid ratio 0.3 means it will be 30 % of data remaning after test_ratio has been splitted. so if test_ratio is 0.3 and valid_ratio is 0.3  valid data will be (1-0.3)*0.3 i.e. 0.21 of total data passed
dt_set <- generte_train_test_validset(X,test_ratio=0.3,valid_ratio=0.3)
train_data <- dt_set$train_data
test_data <- dt_set$test_data
valid_data <- dt_set$valid_data

#write the train_data,test_data and valid_data now to file. Use this in 3rd step of modelling.
#however, you can split them again but make sure that the feature selection part is run once or if you want to repeat it on same data
#to be honest :) .


# Now remove the test and valid data




merge_lvls <- function(trn,tst,vld,alpha= 0.05)
{
X <- trn
factcols <- findallfactorcols(X)
print(factcols)
factcols <- factcols[-1]
cols <- colnames(X)
for (cl in factcols)
{
  ordlvls <- levels(X[,cl])  
  numoflvls <- length(ordlvls)
  while (numoflvls > 2)
  {
    print (cols[cl])
    print(ordlvls)
    print(cl)
    
    ab <- reduce_ord_fact_levels(X[,cl],cls,cols[cl])

    cd <- ab[,4]
    print(max(cd))
    ab_max <- which.max(ab[,4])    
    print(ab_max)
    print(ab)
    max_lvls <- ab[ab_max,]
    print(max_lvls)
    if (max_lvls[,4] < alpha){
      print("I am here")
      break
    }
    else{
      lv2 <- as.numeric(max_lvls$lvl2)
      lv1 <- as.numeric(max_lvls$lvl1)
      print(lv2)
      
      xcl <- as.numeric(as.character(X[,cl]))
      xcl[xcl==lv2] <- lv1           
      X[,cl] <- factor(xcl,levels = ordlvls)
      
      # test data set update
      tcl <- as.numeric(as.character(tst[,cl]))
      tcl[tcl==lv2] <- lv1           
      tst[,cl] <- factor(tcl,levels = ordlvls)
      
      #valid
      # test data set update
      vcl <- as.numeric(as.character(vld[,cl]))
      vcl[vcl==lv2] <- lv1           
      vld[,cl] <- factor(vcl,levels = ordlvls)
      
      postoremove <- which(as.numeric(ordlvls)==lv2)
      ordlvls <- ordlvls[-postoremove] 
      numoflvls <- length(ordlvls)
    }  
    
  }
}
list(X,tst,vld)
}
train_data <- dt_set$train_data
td <- merge_lvls(train_data)
train_data <- td[[1]]
test_data <- td[[2]]
valid_data <- td[[3]]


write.csv(train_data,'fs_train_data.csv',row.names=FALSE)
write.csv(train_data,'fs_test_data.csv',row.names=FALSE)
write.csv(train_data,'fs_validdata.csv',row.names=FALSE)

#pvals <- reduce_levels_for_unord_fact_cols(X)
#print(pvals)

# These are used for all the columns which are ordered factor columns
#pvals <- reduce_levels_for_ord_fact_cols(X)
#print(pvals)

frml1 <- 'Class ~ .'
# Now run the pass 2 and you will see which features to use.
# Here k means how many parameters to bring
# ranking means what ranking to use for random forest. You can pass random forest parameters as well.
findusefulfeatures(train_data,alpha = 0.05,ranking='accuracy',k=20,frml1,ntree=10)
# Did you find features for your model yet . 
# Yes great!!!!!!
# No.  This is why companies need you it is not so easy . Look into those graphs
# Analyse the data again and look at minor details and reiterate this process unless you get it right.

# I fyou find better method than this let me know. 
```

