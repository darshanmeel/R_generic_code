---
output: word_document
---
```{r}
options(warn=-1)
#load the csv file and provide the name as lv
setwd('C:\\Users\\WIN 8.1\\Documents\\GitHub\\R_generic_code\\myrpreprocess\\R')
library(ggplot2)
library(discretization)
library(randomForest)
library(ROCR)
library(myrpreprocess)
library(unbalanced)
filename <- 'LendingClub.csv'
header <- TRUE
filename

clscol='Class'

#run prelim processing
X <- read.csv(file=filename,header=header)
clscolpos <- match(clscol,colnames(X))
X <- X[complete.cases(X),]
X <- moveclasscolintheend(X,clscolpos)
X[,clscolpos] <- as.character(X[,clscolpos])

X[X[,clscolpos]=='Creditworthy',clscolpos] <- '0'
X[X[,clscolpos]=='Uncreditworthy',clscolpos] <- '1'
X[,clscolpos] <- as.factor(as.numeric(X[,clscol]))



#Now fix all the issues you want to with your data which you might have got idea from Pass_1 as well as from your own analytics.

#Now convert all the factor columns to ordered in final model these wont be ordered
factcols <- findallfactorcols(X[,-ncol(X)])
print(factcols)
for (cl in factcols){
  ab <- as.data.frame(table(X[,cl]))
  ab <- ab[order(ab[,2]),]
  nwlvls <- paste(ab[,1],sep=',')
  nwlvls <- as.data.frame(nwlvls)
  nwlvls <- rownames(nwlvls)
  ab <- cbind(ab,nwlvls)
  print (ab)
  X[,cl] <- as.character(X[,cl])
  cl_vc <- X[,cl]
  X[,cl] <- as.numeric(unlist(lapply(cl_vc,function(vl) ab[ab[,1]==vl,3])))
  X[,cl] <- factor(X[,cl], levels = nwlvls)
}


# Now convert these columns to factor columns and in fact ordered factor columns
numcols_to_be_converted <- c(3,8,11,12,13,14,17,18)
X1 <- convert_num_field_to_ordered_fact_cols(X,numcols_to_be_converted,alpha=0.05)
X[,numcols_to_be_converted] <- X1
# see whether new cols are converted to fact columns.
str(X)
# Now break the data into 3 parts, train data, test data and valid data as feature selection should always be done on train data and never on test and valid data.
#valid ratio 0.3 means it will be 30 % of data remaning after test_ratio has been splitted. so if test_ratio is 0.3 and valid_ratio is 0.3  valid data will be (1-0.3)*0.3 i.e. 0.21 of total data passed
dt_set <- generte_train_test_validset(X,test_ratio=0.3,valid_ratio=0.1)
train_data <- dt_set$train_data
test_data <- dt_set$test_data
valid_data <- dt_set$valid_data

#write the train_data,test_data and valid_data now to file. Use this in 3rd step of modelling.
#however, you can split them again but make sure that the feature selection part is run once or if you want to repeat it on same data
#to be honest :) .



train_data <- dt_set$train_data
td <- merge_unord_lvls(train_data,test_data,valid_data)
train_data <- td[[1]]
test_data <- td[[2]]
valid_data <- td[[3]]

str(train_data)

#Now make all the factor columns their own columns
trn_dt <- train_data
cls <- trn_dt[,clscol]
trn_dt[,clscol] <- as.data.frame(NULL)


tst_cls <- test_data[,clscol]
test_data[,clscol] <- as.data.frame(NULL)

valid_cls <- valid_data[,clscol] 
valid_data[,clscol] <- as.data.frame(NULL)

fcl <- findallfactorcols(trn_dt)

for (cl in fcl){

  cols <- colnames(trn_dt)
  lvls <- levels(trn_dt[,cl])
  i <- 0
  for (lvl in lvls){
    cl_suf <- as.character(lvl)
    clname <- paste0(cols[cl],'_',as.character(i))
    trn_dt$cl1 <- as.factor(c(ifelse(trn_dt[,cl]==lvl,1,0)))
    test_data$cl1 <- as.factor(c(ifelse(test_data[,cl]==lvl,1,0)))
    valid_data$cl1 <- as.factor(c(ifelse(valid_data[,cl]==lvl,1,0)))
    cols <- append(cols,clname)
    colnames(trn_dt) <- cols
    colnames(test_data) <- cols
    colnames(valid_data) <- cols
    i <- i + 1
  }

}
colnames(trn_dt)

trn_dt[,fcl] <- as.data.frame(NULL)  
test_data[,fcl] <- as.data.frame(NULL)  
valid_data[,fcl] <- as.data.frame(NULL)  

cols <- colnames(trn_dt)

train_data <- cbind(trn_dt,cls)
test_data <- cbind(test_data,tst_cls)
valid_data <- cbind(valid_data,valid_cls)
cols <- append(cols,clscol)
colnames(train_data ) <- cols
colnames(test_data ) <- cols
colnames(valid_data ) <- cols
clspos <- ncol(train_data)

#write.csv(train_data,'fs_train_data.csv',row.names=FALSE,quote=TRUE)
#write.csv(train_data,'fs_test_data.csv',row.names=FALSE,quote=TRUE)
#write.csv(train_data,'fs_validdata.csv',row.names=FALSE,quote=TRUE)

#pvals <- reduce_levels_for_unord_fact_cols(X)
#print(pvals)

# These are used for all the columns which are ordered factor columns
#pvals <- reduce_levels_for_ord_fact_cols(X)
#print(pvals)



frml1 <- as.formula('Class ~ .')

# Now run the pass 2 and you will see which features to use.
# Here k means how many parameters to bring
# ranking means what ranking to use for random forest. You can pass random forest parameters as well.
findusefulfeatures(train_data,alpha = 0.05,ranking='accuracy',k=20,frml1,ntree=10)
# Did you find features for your model yet . 
# Yes great!!!!!!
# No.  This is why companies need you it is not so easy . Look into those graphs
# Analyse the data again and look at minor details and reiterate this process unless you get it right.

# I fyou find better method than this let me know. 

#now try diff models

train_data$No..Of.Credit.Lines_8 <- NULL
train_data$Total.Number.Of.Credit.Lines_13 <- NULL
train_data$Months.Since.Last.Delinquency_12 <- NULL
train_data$Months.Since.Last.Delinquency_11 <- NULL

valid_data$No..Of.Credit.Lines_8 <- NULL
valid_data$Total.Number.Of.Credit.Lines_13 <- NULL
valid_data$Months.Since.Last.Delinquency_12 <- NULL
valid_data$Months.Since.Last.Delinquency_11 <- NULL


test_data$No..Of.Credit.Lines_8 <- NULL
test_data$Total.Number.Of.Credit.Lines_13 <- NULL
test_data$Months.Since.Last.Delinquency_12 <- NULL
test_data$Months.Since.Last.Delinquency_11 <- NULL

frml1 <- 'Class ~ .'
frml1
frml1 <- as.formula(frml1)
frml1
tst <-train_and_predict_log_reg_and_ret_auc(frml1,train_data,valid_data,predict_type='response')

frml1 <- 'Class ~ Loan.Term_0 + Annual.Income + FICO.Credit.Score_0 + FICO.Credit.Score_1 + Loan.Purpose_0 + No..Inquiries.In.Last.6.Months_2 + FICO.Credit.Score_6 + Address.State_0 + Use.Of.Credit.Line_14 + Use.Of.Credit.Line_13 + No..Adverse.Public.Records_0 + Employment.Length_1 + Loan.Application.Description + Use.Of.Credit.Line_2 + Debt.To.Income.Ratio_1 + Use.Of.Credit.Line_4 + Total.Number.Of.Credit.Lines_1 + Total.Number.Of.Credit.Lines_0 + Earliest.Credit.Line.Opened + No..Inquiries.In.Last.6.Months_0 + Months.Since.Last.Delinquency_6 + Debt.To.Income.Ratio_0 + Total.Number.Of.Credit.Lines_12 + FICO.Credit.Score_2 + Months.Since.Last.Delinquency_4 + No..Inquiries.In.Last.6.Months_1 + Use.Of.Credit.Line_7 + Employment.Length_0 + Use.Of.Credit.Line_9 + No..Of.Public.Record.Bankruptcies_0 + Total.Number.Of.Credit.Lines_3 + No..Of.Credit.Lines_5 + No..Of.Credit.Lines_7 + Total.Number.Of.Credit.Lines_14 + Total.Number.Of.Credit.Lines_10 + Total.Number.Of.Credit.Lines_6 + Total.Number.Of.Credit.Lines_5 + No..Of.Credit.Lines_9 + No..Of.Credit.Lines_2 + Total.Number.Of.Credit.Lines_7 + Total.Number.Of.Credit.Lines_2 + Total.Number.Of.Credit.Lines_9 + Total.Credit.Balance + No..Of.Credit.Lines_3 + Months.Since.Last.Delinquency_2 + No..Of.Credit.Lines_4 + Total.Number.Of.Credit.Lines_11 + Months.Since.Last.Delinquency_10 + Months.Since.Last.Delinquency_1 + No..Of.Public.Record.Bankruptcies_1'
frml1 <- as.formula('Class ~ .')
frml1
frml1 <- as.formula(frml1)
frml1
tst <-train_and_predict_log_reg_and_ret_auc(frml1,train_data,valid_data,predict_type='response')

frml1
rftst <- train_and_predict_random_forest_and_ret_auc(frml1,train_data,valid_data,ntree=500)
# around 0.690
options(warn=0)
```

